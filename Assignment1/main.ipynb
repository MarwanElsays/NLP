{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset,concatenate_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('sst', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'What really surprises about Wisegirls is its low-key quality and genuine tenderness .',\n",
       " 'label': 0.625,\n",
       " 'tokens': 'What|really|surprises|about|Wisegirls|is|its|low-key|quality|and|genuine|tenderness|.',\n",
       " 'tree': '25|24|22|21|21|19|16|15|15|17|14|14|20|18|16|17|18|19|20|23|22|23|24|25|0'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_class(value):\n",
    "    return np.digitize(value, bins=[0.2, 0.4, 0.6, 0.8], right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mapped = dataset.map(lambda example: {'label': map_class(example['label'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the training set\n",
    "train_data = concatenate_datasets([dataset_mapped['train'], dataset_mapped['validation']])\n",
    "train_labels = np.array(train_data['label'],dtype=np.int8)\n",
    "\n",
    "# Access the test set\n",
    "test_data = dataset_mapped['test']\n",
    "test_labels = np.array(test_data['label'],dtype=np.int8)\n",
    "\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'What really surprises about Wisegirls is its low-key quality and genuine tenderness .',\n",
       " 'label': 3.0,\n",
       " 'tokens': 'What|really|surprises|about|Wisegirls|is|its|low-key|quality|and|genuine|tenderness|.',\n",
       " 'tree': '25|24|22|21|21|19|16|15|15|17|14|14|20|18|16|17|18|19|20|23|22|23|24|25|0'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = test_data[10]\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Na√Øve Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(D,num_classes):\n",
    "     \n",
    "    n_doc = len(D)  # Total number of documents/examples\n",
    "    cls_prior = np.zeros(num_classes)  # Initialize class prior probabilities\n",
    "    vocab = set()  # To store the vocabulary\n",
    "    cls_word_cnt = np.array([{} for _ in range(num_classes)])  # Initialize class word counts\n",
    "\n",
    "    # Loop through each example in the dataset\n",
    "    for example in D:\n",
    "        example_class = int(example[\"label\"])  # Get the class label for the example\n",
    "        cls_prior[example_class] += 1  # Count the number of documents for each class\n",
    "        for word in example[\"tokens\"].split(\"|\"):  # Tokenize the example\n",
    "            # Update word count for the corresponding class\n",
    "            cls_word_cnt[example_class][word] = cls_word_cnt[example_class].get(word, 0) + 1\n",
    "            vocab.add(word)  # Add word to the vocabulary\n",
    "           \n",
    "    cls_prior /= n_doc  # Calculate prior probabilities\n",
    "    log_prior = np.log(cls_prior)  # Convert prior probabilities to log space\n",
    "    \n",
    "    vocab_size = len(vocab)\n",
    "    cls_total_word_cnt = np.array([sum(cls_dict.values()) for cls_dict in cls_word_cnt])  # Total word count for each class\n",
    "    \n",
    "    # Calculate log likelihood with smoothing (Laplace smoothing)\n",
    "    log_likelihood = np.array([\n",
    "        {word: np.log((cls_dict.get(word,0) + 1) / (cls_total_word_cnt[i] + vocab_size)) for word in vocab} \n",
    "        for i, cls_dict in enumerate(cls_word_cnt)\n",
    "    ])\n",
    "    \n",
    "    return log_prior, log_likelihood, vocab\n",
    "\n",
    "def test_naive_bayes(test_doc,log_prior, log_likelihood,num_classes,vocab):\n",
    "    sum_lg = np.zeros(num_classes)\n",
    "    for c in range(num_classes):\n",
    "        sum_lg[c] = log_prior[c]\n",
    "        for word in test_doc.split():\n",
    "            if word in vocab:\n",
    "                sum_lg[c] += log_likelihood[c][word]\n",
    "                \n",
    "    return np.argmax(sum_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prior, log_likelihood, vocab = train_naive_bayes(train_data,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for doc in test_data:\n",
    "    predictions.append(test_naive_bayes(doc[\"sentence\"],log_prior, log_likelihood, num_classes, vocab))\n",
    "    \n",
    "predictions = np.array(predictions)\n",
    "\n",
    "# Calculate the number of correct predictions\n",
    "correct_predictions = np.sum(predictions == test_labels)\n",
    "    \n",
    "# Calculate accuracy\n",
    "my_accuracy = correct_predictions / len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3995475113122172\n"
     ]
    }
   ],
   "source": [
    "print(my_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison with scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.40497737556561086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()), \n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(train_data[\"sentence\"], train_labels)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipeline.predict(test_data[\"sentence\"])\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigrams_cnt(D):\n",
    "    \n",
    "    bigrams = {}\n",
    "    for example in D:\n",
    "        words_list = example[\"tokens\"].split(\"|\")\n",
    "        for i in range(len(words_list)-1):\n",
    "            bigram = words_list[i] + \" \" + words_list[i+1]\n",
    "            if bigram not in bigrams:\n",
    "                bigrams[bigram] = len(bigrams)\n",
    "    \n",
    "    return bigrams\n",
    "                \n",
    "def generate_feat(D,bigrams,num_classes):\n",
    "    test_data_feat = np.zeros((len(D),len(bigrams)+1),dtype=np.int8)\n",
    "    test_data_labels = np.zeros((len(D),num_classes),dtype=np.int8)\n",
    "    for i,example in enumerate(D):\n",
    "        test_data_labels[i][int(example[\"label\"])] = 1\n",
    "        words_list = example[\"tokens\"].split(\"|\")\n",
    "        for j in range(len(words_list)-1):\n",
    "            bigram = words_list[j] + \" \" + words_list[j+1]\n",
    "            test_data_feat[i][bigrams[bigram]] = 1\n",
    "            \n",
    "        \n",
    "    return test_data_feat ,test_data_labels     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " ...\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "bigrams = get_bigrams_cnt(train_data)\n",
    "X,Y = generate_feat(train_data,bigrams,num_classes)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X_T:np.ndarray,Y_T:np.ndarray,W:np.ndarray,B:np.ndarray):\n",
    "    soft_max = softmax(W,X_T,B)\n",
    "    req_ind = np.argmax(Y_T, axis=0)  # Row indices of non-zero elements\n",
    "    req_values = np.log(soft_max[req_ind, np.arange(soft_max.shape[1])])\n",
    "    return -np.sum(req_values)\n",
    "\n",
    "def softmax(W:np.ndarray,X_T:np.ndarray,B:np.ndarray):\n",
    "    W_exp = np.exp(W @ X_T + B)\n",
    "    W_exp_sum = np.sum(W_exp,axis = 0)\n",
    "    \n",
    "    return W_exp/W_exp_sum\n",
    "    \n",
    "def calculate_gradient(X:np.ndarray,X_T:np.ndarray,Y_T:np.ndarray,W:np.ndarray,B:np.ndarray):\n",
    "    derivative = Y_T * (1 - softmax(W,X_T,B))\n",
    "    \n",
    "    # Identify the indices of non-zero entries in each column\n",
    "    non_zero_rows = np.argmax(Y_T, axis=0)  # Row indices of non-zero elements\n",
    "    non_zero_values = derivative[non_zero_rows, np.arange(derivative.shape[1])]  # Non-zero values in derivative\n",
    "    \n",
    "    # Vectorized calculation of dW\n",
    "    dW = np.zeros((W.shape[0],W.shape[1]))\n",
    "    np.add.at(dW, non_zero_rows, -non_zero_values[:, np.newaxis] * X)  # Efficient row-wise update\n",
    "    # Calculate dB directly\n",
    "    dB = -np.sum(derivative, axis=1)\n",
    "     \n",
    "    return  dW, dB.reshape(5, 1)\n",
    "       \n",
    "def logistic_regression(X:np.ndarray,Y:np.ndarray,num_classes,lr=0.0001,max_itr=100):\n",
    "    num_examples, num_features = X.shape\n",
    "    W = np.random.rand(num_classes,num_features)\n",
    "    B = np.random.rand(num_classes,1)\n",
    "    itr = 0\n",
    "    X_T,Y_T = X.T, Y.T\n",
    "    while itr < max_itr:\n",
    "        dW, dB = calculate_gradient(X,X_T,Y_T,W,B)\n",
    "        W -= lr * dW\n",
    "        B -= lr * dB\n",
    "        \n",
    "        print(f\"The loss = {loss(X_T,Y_T,W,B)}\")\n",
    "        \n",
    "        itr+=1\n",
    "        \n",
    "    return W,B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42252.84297713096\n",
      "66443.37935055693\n",
      "78696.60686080961\n",
      "61254.64158070224\n",
      "85400.67496971713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1.02059047, 0.96749366, 0.67895187, ..., 0.70139251, 0.47084987,\n",
       "         0.77739312],\n",
       "        [0.59105106, 0.3644622 , 0.11989423, ..., 0.99658006, 0.94958111,\n",
       "         0.50614942],\n",
       "        [0.43494124, 0.92620912, 0.69498505, ..., 0.37714349, 0.89970112,\n",
       "         0.00524143],\n",
       "        [0.87068545, 0.18344192, 0.30527782, ..., 0.46769962, 0.96437839,\n",
       "         0.15547353],\n",
       "        [0.55544599, 0.1356119 , 0.28423066, ..., 0.49598179, 0.71267236,\n",
       "         0.06370952]]),\n",
       " array([[59.62330055],\n",
       "        [82.09219825],\n",
       "        [76.20604668],\n",
       "        [69.79429549],\n",
       "        [69.92429818]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression(X,Y,num_classes,lr=1,max_itr=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison with scikit learn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
