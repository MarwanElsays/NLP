{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset,concatenate_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('sst', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'What really surprises about Wisegirls is its low-key quality and genuine tenderness .',\n",
       " 'label': 0.625,\n",
       " 'tokens': 'What|really|surprises|about|Wisegirls|is|its|low-key|quality|and|genuine|tenderness|.',\n",
       " 'tree': '25|24|22|21|21|19|16|15|15|17|14|14|20|18|16|17|18|19|20|23|22|23|24|25|0'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_class(value):\n",
    "    return np.digitize(value, bins=[0.2, 0.4, 0.6, 0.8], right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mapped = dataset.map(lambda example: {'label': map_class(example['label'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the training set\n",
    "train_data = concatenate_datasets([dataset_mapped['train'], dataset_mapped['validation']])\n",
    "train_labels = np.array(train_data['label'],dtype=np.int8)\n",
    "\n",
    "# Access the test set\n",
    "test_data = dataset_mapped['test']\n",
    "test_labels = np.array(test_data['label'],dtype=np.int8)\n",
    "\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'What really surprises about Wisegirls is its low-key quality and genuine tenderness .',\n",
       " 'label': 3.0,\n",
       " 'tokens': 'What|really|surprises|about|Wisegirls|is|its|low-key|quality|and|genuine|tenderness|.',\n",
       " 'tree': '25|24|22|21|21|19|16|15|15|17|14|14|20|18|16|17|18|19|20|23|22|23|24|25|0'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = test_data[10]\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Na√Øve Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(D,num_classes):\n",
    "     \n",
    "    n_doc = len(D)  # Total number of documents/examples\n",
    "    cls_prior = np.zeros(num_classes)  # Initialize class prior probabilities\n",
    "    vocab = set()  # To store the vocabulary\n",
    "    cls_word_cnt = np.array([{} for _ in range(num_classes)])  # Initialize class word counts\n",
    "\n",
    "    # Loop through each example in the dataset\n",
    "    for example in D:\n",
    "        example_class = int(example[\"label\"])  # Get the class label for the example\n",
    "        cls_prior[example_class] += 1  # Count the number of documents for each class\n",
    "        for word in example[\"tokens\"].split(\"|\"):  # Tokenize the example\n",
    "            # Update word count for the corresponding class\n",
    "            cls_word_cnt[example_class][word] = cls_word_cnt[example_class].get(word, 0) + 1\n",
    "            vocab.add(word)  # Add word to the vocabulary\n",
    "           \n",
    "    cls_prior /= n_doc  # Calculate prior probabilities\n",
    "    log_prior = np.log(cls_prior)  # Convert prior probabilities to log space\n",
    "    \n",
    "    vocab_size = len(vocab)\n",
    "    cls_total_word_cnt = np.array([sum(cls_dict.values()) for cls_dict in cls_word_cnt])  # Total word count for each class\n",
    "    \n",
    "    # Calculate log likelihood with smoothing (Laplace smoothing)\n",
    "    log_likelihood = np.array([\n",
    "        {word: np.log((cls_dict.get(word,0) + 1) / (cls_total_word_cnt[i] + vocab_size)) for word in vocab} \n",
    "        for i, cls_dict in enumerate(cls_word_cnt)\n",
    "    ])\n",
    "    \n",
    "    return log_prior, log_likelihood, vocab\n",
    "\n",
    "def test_naive_bayes(test_doc,log_prior, log_likelihood,num_classes,vocab):\n",
    "    sum_lg = np.zeros(num_classes)\n",
    "    for c in range(num_classes):\n",
    "        sum_lg[c] = log_prior[c]\n",
    "        for word in test_doc.split():\n",
    "            if word in vocab:\n",
    "                sum_lg[c] += log_likelihood[c][word]\n",
    "                \n",
    "    return np.argmax(sum_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prior, log_likelihood, vocab = train_naive_bayes(train_data,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for doc in test_data:\n",
    "    predictions.append(test_naive_bayes(doc[\"sentence\"],log_prior, log_likelihood, num_classes, vocab))\n",
    "    \n",
    "predictions = np.array(predictions)\n",
    "\n",
    "# Calculate the number of correct predictions\n",
    "correct_predictions = np.sum(predictions == test_labels)\n",
    "    \n",
    "# Calculate accuracy\n",
    "my_accuracy = correct_predictions / len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3995475113122172\n"
     ]
    }
   ],
   "source": [
    "print(my_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison with scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.40497737556561086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()), \n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(train_data[\"sentence\"], train_labels)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipeline.predict(test_data[\"sentence\"])\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigrams_cnt(D):\n",
    "    \n",
    "    bigrams = {}\n",
    "    for example in D:\n",
    "        words_list = example[\"tokens\"].split(\"|\")\n",
    "        for i in range(len(words_list)-1):\n",
    "            bigram = words_list[i] + \" \" + words_list[i+1]\n",
    "            if bigram not in bigrams:\n",
    "                bigrams[bigram] = len(bigrams)\n",
    "    \n",
    "    return bigrams\n",
    "                \n",
    "def generate_feat(D,bigrams,num_classes):\n",
    "    test_data_feat = np.zeros((len(D),len(bigrams)+1),dtype=np.int8)\n",
    "    test_data_labels = np.zeros((len(D),num_classes),dtype=np.int8)\n",
    "    for i,example in enumerate(D):\n",
    "        test_data_labels[i][int(example[\"label\"])] = 1\n",
    "        words_list = example[\"tokens\"].split(\"|\")\n",
    "        for j in range(len(words_list)-1):\n",
    "            bigram = words_list[j] + \" \" + words_list[j+1]\n",
    "            if bigram in bigrams:\n",
    "                test_data_feat[i][bigrams[bigram]] = 1\n",
    "            \n",
    "        \n",
    "    return test_data_feat ,test_data_labels     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9645, 5)\n",
      "9645\n",
      "[[0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " ...\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "bigrams = get_bigrams_cnt(train_data)\n",
    "X,Y = generate_feat(train_data,bigrams,num_classes)\n",
    "print(Y.shape)\n",
    "print(len(X))\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(X, Y, batch_size):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        batch_X = X[i:min(i + batch_size,len(X))]\n",
    "        batch_Y = Y[i:min(i + batch_size,len(X))]\n",
    "        yield batch_X, batch_Y\n",
    "\n",
    "def softmax(X:np.ndarray,W:np.ndarray,B:np.ndarray):  \n",
    "    W_exp = np.exp(X @ W + B )   #N*f x f*c = N*c\n",
    "    W_exp_sum = np.sum(W_exp,axis = 1).reshape(-1,1)\n",
    "\n",
    "    return W_exp/W_exp_sum\n",
    "\n",
    "def loss(X:np.ndarray,Y:np.ndarray,W:np.ndarray,B:np.ndarray):\n",
    "    soft_max = softmax(X,W,B)\n",
    "    req_ind = np.argmax(Y, axis=1)  # Row indices of non-zero elements\n",
    "    req_values = np.log(soft_max[np.arange(soft_max.shape[0]),req_ind])\n",
    "   \n",
    "    return -1/X.shape[0]*np.sum(req_values)\n",
    "    \n",
    "def calculate_gradient(X:np.ndarray,Y:np.ndarray,W:np.ndarray,B:np.ndarray,num_classes):\n",
    "    p = Y - softmax(X,W,B)\n",
    "    dB = -np.sum(p, axis=0).reshape(1,num_classes)\n",
    "    wB = -X.T@p\n",
    "    \n",
    "    return  wB,dB\n",
    "          \n",
    "def logistic_regression(X:np.ndarray,Y:np.ndarray,num_classes,lr=0.0001,max_itr=100,batch_size=15):\n",
    "    num_examples, num_features = X.shape\n",
    "    W = np.zeros((num_features,num_classes))\n",
    "    v_dw = np.zeros((num_features,num_classes))\n",
    "    s_dw = np.zeros((num_features,num_classes))\n",
    "    B = np.zeros((1,num_classes))\n",
    "    v_db = np.zeros((1,num_classes))\n",
    "    s_db = np.zeros((1,num_classes))\n",
    "    # Initialize variables to store the best loss and model parameters\n",
    "    best_loss = float('inf')\n",
    "    best_W = None\n",
    "    best_B = None\n",
    "    itr = 0\n",
    "    b1 = 0.9\n",
    "    b2 = 0.999\n",
    "    eta = 1e-8\n",
    "    while itr < max_itr:\n",
    "        print(f\"itr{itr+1}:\")\n",
    "        print(\"=============================================================================\")\n",
    "        for batch_X, batch_Y in create_batches(X, Y, batch_size):\n",
    "            \n",
    "            dW, dB = calculate_gradient(batch_X,batch_Y,W,B,num_classes)  \n",
    "            v_dw = b1 * v_dw + (1-b1)*dW\n",
    "            v_db =  b1 * v_db + (1-b1)*dB\n",
    "            \n",
    "            s_dw = b2 * s_dw + (1-b2)*dW**2\n",
    "            s_db = b2 * s_db + (1-b2)*dB**2\n",
    "            \n",
    "            W -= lr * v_dw / (s_dw + eta) ** 0.5\n",
    "            B -= lr * v_db / (s_db + eta) ** 0.5\n",
    "\n",
    "            current_loss = loss(batch_X,batch_Y,W,B)\n",
    "            print(f\"The loss = {current_loss}\")\n",
    "            \n",
    "            if current_loss < best_loss:\n",
    "                best_loss = current_loss\n",
    "                best_W = W.copy()  # Save the current best weights\n",
    "                best_B = B.copy()  # Save the current best biases\n",
    "        \n",
    "        print(\"=============================================================================\")\n",
    "\n",
    "        itr+=1\n",
    "    print(best_loss)\n",
    "    return W, B, best_W, best_B\n",
    "\n",
    "def predict(X,W,B):\n",
    "    return np.argmax(softmax(X,W,B),axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, B, best_W, best_B = logistic_regression(X,Y,num_classes,lr=0.01,max_itr=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,Y_test = generate_feat(test_data,bigrams,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.334841628959276"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels = predict(X_test,W, B)\n",
    "\n",
    "accuracy = np.sum(pred_labels == test_labels)/len(test_labels)\n",
    "accuracy\n",
    "# loss(X,Y,best_W,best_B)\n",
    "# loss(X,Y,W,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"last_model.npz\", W=W, B=B)\n",
    "np.savez(\"best_model.npz\", W=best_W, B=best_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.351131221719457"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the .npz file\n",
    "data = np.load(\"best_model.npz\")\n",
    "\n",
    "# Access the W and B matrices\n",
    "W = data[\"W\"]\n",
    "B = data[\"B\"]\n",
    "\n",
    "pred = predict(X_test,W,B)\n",
    "\n",
    "np.sum(pred == test_labels)/len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison with scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Initialize LogisticRegression\n",
    "clf_logreg = LogisticRegression(max_iter=100, multi_class='multinomial', solver='lbfgs')\n",
    "clf_logreg.fit(X, train_labels)  # Assuming X_train, Y_train are your training sets\n",
    "\n",
    "\n",
    "# Initialize SGDClassifier as logistic regression\n",
    "clf_sgd = SGDClassifier(loss='log_loss', max_iter=100, tol=1e-3, learning_rate='optimal', penalty='l2')\n",
    "clf_sgd.fit(X, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logreg = clf_logreg.predict(X_test)\n",
    "y_pred_sgd = clf_sgd.predict(X_test)\n",
    "\n",
    "accuracy = np.sum(y_pred_logreg == test_labels)/len(test_labels)\n",
    "print(f\"logisitc regression accuracy = {accuracy}\")\n",
    "\n",
    "accuracy = np.sum(y_pred_sgd == test_labels)/len(test_labels)\n",
    "print(f\"SGD accuracy = {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
